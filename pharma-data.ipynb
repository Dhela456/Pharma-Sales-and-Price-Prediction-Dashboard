{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15e8a519",
   "metadata": {},
   "source": [
    "# Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a34ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/cleaned_pharma_data.csv')\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2771685",
   "metadata": {},
   "source": [
    "#### Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0054e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e23f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286af52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6cb3e",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70c6465",
   "metadata": {},
   "source": [
    "### Data fix - Getting rid of unwanted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff14186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Quantity'] = df['Quantity'].abs()\n",
    "df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0827b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sales'] = df['Sales'].abs()\n",
    "df['Sales'] = pd.to_numeric(df['Sales'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5106ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Customer Name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926ba6b2",
   "metadata": {},
   "source": [
    "### Data Type Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3636583",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Quantity'] = df['Quantity'].abs().astype(float)\n",
    "df['Sales'] = df['Sales'].abs().astype(float)\n",
    "df['Price'] = df['Price'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff6bc24",
   "metadata": {},
   "source": [
    "### Duplicate Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e06462",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duplicate Rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002cda11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e07ee9",
   "metadata": {},
   "source": [
    "### Outlier Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b9081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_anomalies(df):\n",
    "    anomalies = []\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "    for outlier in df:\n",
    "        if outlier > upper_limit or outlier < lower_limit:\n",
    "            anomalies.append(outlier)\n",
    "    return anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb98133c",
   "metadata": {},
   "source": [
    "#### Sales Outlier Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee87828",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_outlier = find_anomalies(df['Sales'])\n",
    "df = df[~df['Sales'].isin(sales_outlier)]\n",
    "len(sales_outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972a9d63",
   "metadata": {},
   "source": [
    "#### Quantity Outlier Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac71603",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity_outlier = find_anomalies(df['Sales'])\n",
    "df = df[~df['Quantity'].isin(quantity_outlier)]\n",
    "len(quantity_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b8eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data after outlier removal: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.select_dtypes('float64')\n",
    "sns.boxplot(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afad7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('cleaned_pharma_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850fb1e8",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d593c0",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67638c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df[['Quantity', 'Price', 'Sales', 'Year']]\n",
    "cols.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29ffc56",
   "metadata": {},
   "source": [
    "#### HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d38c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['Quantity', 'Price', 'Sales', 'Year']\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.heatmap(df[numeric_cols].corr(), cmap='coolwarm', linewidths=0.5, annot=True, linecolor='black')\n",
    "plt.title('HeatMap: Correlation of Numerical Features')\n",
    "#plt.savefig('HeatMap: Correlation of Numerical Features.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c4803a",
   "metadata": {},
   "source": [
    "### Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94850aae",
   "metadata": {},
   "source": [
    "#### Product Name and Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a0af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_sales = df.groupby(['Product Name', 'Product Class'])['Sales'].agg(['mean', 'sum']).round(0)\n",
    "product_sales = product_sales.rename(columns={'mean': 'Avg Sales ($)', 'sum': 'Total Sales ($)'})\n",
    "product_sales.sort_values(by='Total Sales ($)', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e5aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Product Class', y='Sales', data=df, hue='Product Class', legend=False, errorbar=None, palette='Set1', estimator='sum')\n",
    "plt.title('Total Sales of Each Product Class')\n",
    "plt.xlabel('Product Class')\n",
    "plt.xticks(rotation=(60))\n",
    "plt.ylabel('Sales ($)')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Total Sales of Each Product Class.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aa4e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Product Class', y='Sales', data=df, hue='Product Class', errorbar=None, palette='Set1', legend=False)\n",
    "plt.title('Max Sales by Class')\n",
    "plt.xlabel('Product Class')\n",
    "plt.ylabel('Sales ($)')\n",
    "plt.xticks(rotation=(45))\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Max Sales by Product Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d983284",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_sales = df.groupby(['Channel', 'Sub-channel'])['Sales'].agg(['mean', 'sum'])\n",
    "channel_sales = channel_sales.rename(columns={'mean': 'Avg Sales ($)', 'sum': 'Total Sales ($)'})\n",
    "channel_sales.sort_values(by='Total Sales ($)', ascending=False)          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c7f41",
   "metadata": {},
   "source": [
    "#### Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dfdc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_sales = df.groupby(['Product Class', 'Year'])['Sales'].agg(['mean', 'sum'])\n",
    "yearly_sales = yearly_sales.rename(columns={'mean': 'Avg Sales ($)', 'sum': 'Total Sales ($)'})\n",
    "yearly_sales.sort_values(by='Total Sales ($)', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425326d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "sns.barplot(x='Product Class', y='Sales', data=df, hue='Year', errorbar=None, estimator='sum')\n",
    "plt.title('Total Sales by Product Class and Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Sales ($)')\n",
    "plt.legend(title=('Channels'), loc='lower left')\n",
    "#plt.savefig('Total Sales by Product Class and Years.png')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a651d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='Year', y='Sales', data=df, errorbar=None, estimator='sum')\n",
    "plt.title('Total Sales by Year')\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Sales ($)')\n",
    "#plt.savefig('Total Sales by Year.png')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35d43d5",
   "metadata": {},
   "source": [
    "#### Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34985883",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.barplot(x='Month', y='Sales', data=df, hue='Year', estimator='sum', palette='Set2', errorbar=None)\n",
    "plt.title('Total Sales by Month and Year')\n",
    "plt.xlabel('Months')\n",
    "plt.ylabel('Total Sales ($)')\n",
    "plt.legend(title='Years')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Total Sales by Month and Year.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d58218",
   "metadata": {},
   "source": [
    "### Distributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee43808",
   "metadata": {},
   "source": [
    "#### Distributors by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd85915",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributor_sales = df.groupby(['Distributor', 'Country'])['Sales'].agg(['mean', 'sum'])\n",
    "distributor_sales = distributor_sales.rename(columns={'mean': 'Avg Sales ($)', 'sum': 'Total Sales ($)'})\n",
    "distributor_sales = distributor_sales.sort_values(by='Total Sales ($)', ascending=False)\n",
    "distributor_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8accb8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributor_sales.plot(kind='barh', title=('Distributor by Total Sales'), xlabel='Total Sales', ylabel='Distributor', legend=False, figsize=(9, 6))\n",
    "plt.gca().invert_yaxis()\n",
    "#plt.savefig('Distributor by Total Sales.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa8c4e6",
   "metadata": {},
   "source": [
    "#### Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cba731",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity_dist = df.groupby(['Distributor', 'Country'])['Quantity'].agg(['mean', 'sum']).round(0)\n",
    "quantity_dist = quantity_dist.rename(columns={'mean': 'Avg Quantity', 'sum': 'Total Quantity'})\n",
    "quantity_dist = quantity_dist.sort_values(by='Total Quantity', ascending=False)\n",
    "quantity_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac2a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributor_sales.plot(kind='barh', title=('Distributor by Quantity'), xlabel='Quantity', ylabel='Distributor', legend=False, figsize=(9, 6))\n",
    "plt.gca().invert_yaxis()\n",
    "#plt.savefig('Distributor by Quantity.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dde28ed",
   "metadata": {},
   "source": [
    "### Sales Teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057398b4",
   "metadata": {},
   "source": [
    "#### Sales Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a87a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_team = df.groupby(['Name of Sales Rep', 'Sales Team'])['Sales'].agg(['mean', 'sum']).round(0)\n",
    "sales_team = sales_team.rename(columns={'mean': 'Avg Sales ($)', 'sum': 'Total Sales ($)'})\n",
    "sales_team = sales_team.sort_values(by='Total Sales ($)', ascending=False)\n",
    "sales_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b80e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_rep = df.groupby('Name of Sales Rep')['Sales'].sum().reset_index()\n",
    "plt.figure(figsize=(9, 6))\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(sales_team)))\n",
    "explode = [0.1 if Name == 'Jimmy Grey' else 0 for Name in sales_rep['Name of Sales Rep']]\n",
    "plt.pie(sales_rep['Sales'], labels=sales_rep['Name of Sales Rep'], autopct='%1.1f%%', explode=explode, shadow=True, startangle=90, colors=colors)\n",
    "plt.title('Total Sales by Sales Rep', fontsize=14, pad=20)\n",
    "plt.axis('equal')\n",
    "#plt.savefig('Total Sales by Sales Rep.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a726082",
   "metadata": {},
   "source": [
    "#### Sales Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16070663",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "sns.barplot(x='Sales', y='Sales Team', data=df, hue='Manager', estimator='sum', errorbar=None, palette='Set1')\n",
    "plt.title('Total Sales by Sales Team and Manager')\n",
    "plt.xlabel('Total Sales ($)')\n",
    "plt.ylabel('Sales Team')\n",
    "#plt.savefig('Total Sales by Sales Team and Manager.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2d65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_sales = df.groupby('Sales Team')['Sales'].sum().reset_index()\n",
    "plt.figure(figsize=(9, 6))\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(team_sales)))\n",
    "explode = [0.1 if team == 'Delta' else 0 for team in team_sales['Sales Team']]\n",
    "plt.pie(team_sales['Sales'], labels=team_sales['Sales Team'], autopct='%1.1f%%', explode=explode, shadow=True, startangle=90, colors=colors)\n",
    "plt.title('Total Sales by Sales Team', fontsize=14, pad=20)\n",
    "plt.legend(team_sales['Sales'], title='Sales Teams', loc='best')\n",
    "plt.axis('equal')\n",
    "#plt.savefig('Total Sales by Sales team.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2c3f94",
   "metadata": {},
   "source": [
    "## ML Models for Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6206f56",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4552ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Quantity_Price'] = df['Quantity'] * df['Price']\n",
    "features = ['Distributor', 'City', 'Country', 'Channel', 'Sub-channel',\n",
    "            'Product Name', 'Product Class', 'Quantity', 'Month', \n",
    "            'Year', 'Name of Sales Rep', 'Manager', 'Sales Team']\n",
    "target_sales = 'Sales'\n",
    "target_price = 'Price'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a5c58",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1102131",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['Distributor', 'Customer Name', 'City', 'Country', 'Channel', \n",
    "                      'Sub-channel', 'Product Name', 'Product Class', \n",
    "                      'Name of Sales Rep', 'Manager', 'Sales Team', 'Month']\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4563eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {} \n",
    "encoded_data = []  \n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:  \n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str)) \n",
    "        label_encoders[col] = le  \n",
    "        encoded_data.append(col)\n",
    "        print(f\"Encoded {col}: {df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30063c45",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5eda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['Quantity', 'Year']\n",
    "scaled_data = []\n",
    "for col in numeric_columns:\n",
    "    if col in df.columns:\n",
    "        scaler = StandardScaler()\n",
    "        df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "        scaled_data.append(col)\n",
    "        print(f\"Scaled {col}: {df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a549518",
   "metadata": {},
   "source": [
    "### Sales Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be71cd59",
   "metadata": {},
   "source": [
    "#### Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3305c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_sales = features + ['Price', 'Quantity_Price']\n",
    "X_sales = df[features_for_sales]\n",
    "y_sales = df[target_sales]\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_sales, y_sales, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75993c6c",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34317991",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sales = {'learning_rate':0.1,\n",
    "         'max_depth':5,\n",
    "         'subsample':1.0,\n",
    "         'colsample_bytree':1.0,\n",
    "         'lambda':5.0,\n",
    "         'alpha':0.5,\n",
    "         'min_child_weight':5\n",
    "         }\n",
    "model_sales = xgb.XGBRegressor(objective='reg:squarederror', **param_sales, random_state=42, n_jobs=-1, n_estimators=100, enable_categorical=True)\n",
    "model_sales.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab533689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model Predictions for testing data\n",
    "y_pred_s = model_sales.predict(X_test_s)\n",
    "\n",
    "# Model Predictions for training Data\n",
    "y_train_pred_s = model_sales.predict(X_train_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9016f63f",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079dd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaulation for Testing Data\n",
    "mse_sales = mean_squared_error(y_test_s, y_pred_s)\n",
    "rmse_sales = np.sqrt(mse_sales)\n",
    "mae_sales = mean_absolute_error(y_test_s, y_pred_s)\n",
    "r2_sales = r2_score(y_test_s, y_pred_s)\n",
    "print('Model Evaluation Metrics for Sales Prediction (Testing Data):')\n",
    "print(f\"Mean Squared Error: {mse_sales:.2f}, RMSE: {rmse_sales:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae_sales:.2f}\")\n",
    "print(f\"R2 Score: {r2_sales:.2f}\")\n",
    "\n",
    "dmatrix_sales = xgb.DMatrix(X_train_s, label=y_train_s)\n",
    "sales_cv = xgb.cv(param_sales, dtrain=dmatrix_sales, num_boost_round=100, nfold=5, metrics='rmse', early_stopping_rounds=10)\n",
    "print(\"\\nCross Validation Resuts for Sales Model:\")\n",
    "print(sales_cv.tail())\n",
    "\n",
    "# Evaluaton for Training Data\n",
    "mse_train_sales = mean_squared_error(y_train_s, y_train_pred_s)\n",
    "rmse_train_sales = np.sqrt(mse_train_sales)\n",
    "mae_train_sales = mean_absolute_error(y_train_s, y_train_pred_s)\n",
    "r2_train_sales = r2_score(y_train_s, y_train_pred_s)\n",
    "print('Model Evaluation Metrics for Sales Prediction (Training Data):')\n",
    "print(f\"\\nMean Squared Error: {mse_train_sales:.2f}, RMSE: {rmse_train_sales:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae_train_sales:.2f}\")\n",
    "print(f\"R2 Score: {r2_train_sales:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfd0e7f",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f00c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'green', 'blue', 'purple', 'orange']\n",
    "plt.scatter(y_test_s, y_pred_s, alpha=0.5, label='Sales')\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.title('XGBoost: Actual vs Predicted Sales')\n",
    "plt.plot([min(y_test_s), max(y_test_s)], [min(y_test_s), max(y_test_s)], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04176c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sales_cv.index + 1, sales_cv['train-rmse-mean'], label='Train Mean')\n",
    "plt.plot(sales_cv.index + 1, sales_cv['test-rmse-mean'], label='Test Mean')\n",
    "plt.fill_between(sales_cv.index + 1, \n",
    "                 sales_cv['train-rmse-mean'] - sales_cv['train-rmse-std'],\n",
    "                 sales_cv['train-rmse-mean'] + sales_cv['train-rmse-std'], alpha=0.2)\n",
    "plt.fill_between(sales_cv.index + 1, \n",
    "                 sales_cv['test-rmse-mean'] - sales_cv['test-rmse-std'],\n",
    "                 sales_cv['test-rmse-mean'] + sales_cv['test-rmse-std'], alpha=0.2)\n",
    "plt.xlabel('Boosting Rounds')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('CV Learning Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951cdf06",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f14d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_importance_df = pd.DataFrame({\n",
    "    'Feature': features_for_sales, \n",
    "    'Importance': model_sales.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False).reset_index().drop('index', axis=1)\n",
    "sales_importance_df = sales_importance_df[1:]\n",
    "sales_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb2100",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(sales_importance_df['Feature'], sales_importance_df['Importance'], color='skyblue')\n",
    "plt.title('Feature Importance for Sales')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70321031",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(model_sales, max_num_features=10, title='XGBoost: Feature Importance (Sales)', grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f22129",
   "metadata": {},
   "source": [
    "### Price Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb67d4a",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_price = [f for f in features if f not in ['Quantity', 'Quantity_Price']]\n",
    "X_price = df[features_for_price]\n",
    "y_price = df[target_price]\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_price, y_price, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31276ee1",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90468476",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_price = {'learning_rate':0.5,\n",
    "         'max_depth':9,\n",
    "         'subsample':1.0,\n",
    "         'colsample_bytree':1.0,\n",
    "         'min_child_weight':1.0,\n",
    "         'eta':0.05,\n",
    "         'lambda':0.1,\n",
    "         'alpha':0\n",
    "}\n",
    "model_price = xgb.XGBRegressor(objective='reg:squarederror', **param_price, n_estimators=300, random_state=42, enable_categorical=True)\n",
    "model_price.fit(X_train_p, y_train_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355269f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model Prediction for Testing Data\n",
    "y_pred_p = model_price.predict(X_test_p)\n",
    "\n",
    "# Initialize Model Prediction for Training Data\n",
    "y_train_pred_p = model_price.predict(X_train_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea05a131",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490fbd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaulation for Testing Data\n",
    "mse_price = mean_squared_error(y_test_p, y_pred_p)\n",
    "rmse_price = np.sqrt(mse_price)\n",
    "mae_price = mean_absolute_error(y_test_p, y_pred_p)\n",
    "r2_price = r2_score(y_test_p, y_pred_p)\n",
    "print('Model Evaluation Metrics for Price Prediction (Testing Data):')\n",
    "print(f\"Mean Squared Error: {mse_price:.2f}, RMSE: {rmse_price:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae_price:.2f}\")\n",
    "print(f\"R2 Score: {r2_price:.2f}\")\n",
    "\n",
    "dmatrix_price = xgb.DMatrix(X_train_p, label=y_train_p)\n",
    "price_cv = xgb.cv(param_price, dtrain=dmatrix_price, num_boost_round=100, nfold=5, metrics='rmse', early_stopping_rounds=10)\n",
    "print(\"\\nCross Validation Resuts for Price Model:\")\n",
    "print(price_cv.tail())\n",
    "\n",
    "# Evaluaton for Training Data\n",
    "mse_train_price = mean_squared_error(y_train_p, y_train_pred_p)\n",
    "rmse_train_price = np.sqrt(mse_train_price)\n",
    "mae_train_price = mean_absolute_error(y_train_p, y_train_pred_p)\n",
    "r2_train_price = r2_score(y_train_p, y_train_pred_p)\n",
    "print('Model Evaluation Metrics for Price Prediction (Training Data):')\n",
    "print(f\"\\nMean Squared Error: {mse_train_price:.2f}, RMSE: {rmse_train_price:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae_train_price:.2f}\")\n",
    "print(f\"R2 Score: {r2_train_price:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24891a79",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2aed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'green', 'blue', 'purple', 'orange']\n",
    "plt.scatter(y_test_p, y_pred_p, alpha=0.5, label='Price')\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.title('XGBoost: Actual vs Predicted Prices')\n",
    "plt.plot([min(y_test_p), max(y_test_p)], [min(y_test_p), max(y_test_p)], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1ed65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(price_cv.index + 1, price_cv['train-rmse-mean'], label='Train Mean')\n",
    "plt.plot(price_cv.index + 1, price_cv['test-rmse-mean'], label='Test Mean')\n",
    "plt.fill_between(price_cv.index + 1, \n",
    "                 price_cv['train-rmse-mean'] - price_cv['train-rmse-std'],\n",
    "                 price_cv['train-rmse-mean'] + price_cv['train-rmse-std'], alpha=0.2)\n",
    "plt.fill_between(price_cv.index + 1, \n",
    "                 price_cv['test-rmse-mean'] - price_cv['test-rmse-std'],\n",
    "                 price_cv['test-rmse-mean'] + price_cv['test-rmse-std'], alpha=0.2)\n",
    "plt.xlabel=('Boosting Rounds')\n",
    "plt.ylabel=('RMSE')\n",
    "plt.title('CV Learning Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6111694",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de45ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train_p.columns, \n",
    "    'Importance': model_price.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False).reset_index().drop('index', axis=1)\n",
    "price_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114ddf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(price_importance_df['Feature'], price_importance_df['Importance'], color='skyblue')\n",
    "plt.title('Feature Importance for Price')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(model_price, max_num_features=10, title='XGBoost: Feature Importance (Price)', grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776364ab",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7528115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_new_data(new_data, model_sales, model_price, label_encoders, scaler, features_for_sales,\n",
    "                     features_for_price, categorical_columns, numeric_columns):\n",
    "    new_data_df = pd.DataFrame(new_data)\n",
    "    # Encode categorical columns\n",
    "    for col in categorical_columns:\n",
    "        if col in new_data_df.columns:\n",
    "            le = label_encoders[col]\n",
    "            # Add 'Unknown' to classes if needed\n",
    "            if 'Unknown' not in le.classes_:\n",
    "                le.classes_ = np.append(le.classes_, 'Unknown')\n",
    "            new_data_df[col] = new_data_df[col].apply(lambda x: x if x in le.classes_ else 'Unknown')\n",
    "            new_data_df[col] = le.transform(new_data_df[col])\n",
    "    \n",
    "    # Scale numeric features\n",
    "    input_data_as_array = np.asarray(new_data_df[numeric_columns])\n",
    "    std_data = scaler.inverse_transform(input_data_as_array.reshape(1, -1)).flatten()\n",
    "    new_data_df[numeric_columns] = std_data\n",
    "\n",
    "    # Select only the columns used for training, in the correct order\n",
    "    X_sales_pred = new_data_df.reindex(columns=features_for_sales, fill_value=0)\n",
    "    X_price_pred = new_data_df.reindex(columns=features_for_price, fill_value=0)\n",
    "    # Predict sales and price\n",
    "    price_prediction = model_price.predict(X_price_pred)\n",
    "    sales_prediction = price_prediction * new_data_df['Quantity']\n",
    "\n",
    "    return sales_prediction, price_prediction\n",
    "\n",
    "\n",
    "new_data_df = {\n",
    "    'Distributor': ['Gottlieb-Cruickshank'],\n",
    "    'Customer Name': ['Keeling LLC Pharmacy'],\n",
    "    'City': ['Olsztyn'],\n",
    "    'Country': ['Poland'],\n",
    "    'Channel': ['Pharmacy'],\n",
    "    'Sub-channel': ['Private'],\n",
    "    'Product Name': ['Oxymotroban Fexoformin'],\n",
    "    'Product Class': ['Analgesics'],\n",
    "    'Quantity': [20.0],\n",
    "  #  'Price': [368.0],\n",
    "    #'Sales': [1472.0],\n",
    "    'Month': ['January'],\n",
    "    'Year': [2018],\n",
    "    'Name of Sales Rep': ['Anne Wu'],\n",
    "    'Manager': ['Britanny Bold'],\n",
    "    'Sales Team': ['Delta']\n",
    "#    'Quantity_Price': [1472.0]  \n",
    "}\n",
    "sales_prediction, price_prediction = predict_new_data(new_data_df, model_sales, model_price, label_encoders, scaler, features_for_sales, features_for_price, categorical_columns, numeric_columns)\n",
    "results = pd.DataFrame({\n",
    "    'Predicted Sales ($)': sales_prediction.round(2),\n",
    "  #  'Actual Sales ($)': new_data_df['Sales'],\n",
    "    'Predicted Price ($)': price_prediction.round(2),\n",
    "  #  'Actual Price ($)': new_data_df['Price']\n",
    "})\n",
    "print(\"Predictions for New Data:\")\n",
    "for col in results.columns:\n",
    "    results[col] = results[col].astype(int)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13a67fd",
   "metadata": {},
   "source": [
    "### Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317331f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'model_artifacts'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "pipeline = {\n",
    "    'features_for_sales': features_for_sales,\n",
    "    'features_for_price': features_for_price,\n",
    "    'label_encoders': label_encoders,\n",
    "    'scaler': scaler, \n",
    "    'model_sales': model_sales,\n",
    "    'model_price': model_price,\n",
    "    'categorical_columns': categorical_columns,\n",
    "    'numeric_columns': numeric_columns,\n",
    "    'sales_importance_df': sales_importance_df,\n",
    "    'price_importance_df': price_importance_df\n",
    "}\n",
    "joblib.dump(pipeline, os.path.join(save_dir, 'pipeline.joblib'))\n",
    "print(f\"All components saved to '{save_dir}' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114cb5a7",
   "metadata": {},
   "source": [
    "### Readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f59a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('Readme.md', 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "# Prediction and Dashboard for Pharma Sales and Price.\n",
    "**Objective**: This Project focuses on the prediction of Pharma Sales and Price as well as a detailed Dashboard Analysis.\n",
    "\n",
    "## Table of Contents\n",
    "- [Data Overview](#data-overview)\n",
    "- [Data Cleaning](#data-cleaning)\n",
    "- [Exploratory Data Analysis (EDA)](#exploratory-data-analysis-eda)\n",
    "- [Machine Learning Models](#machine-learning-models)\n",
    "- [Data Preprocessing](#data-preprocessing)\n",
    "- [Feature Engineering](#feature-engineering)\n",
    "- [Model Training & Evaluation](#model-training--evaluation)\n",
    "- [Feature Importance](#feature-importance)\n",
    "- [Predictions on New Data](#predictions-on-new-data)\n",
    "- [Model Artifacts](#model-artifacts)\n",
    "- [Dashboard Creation](#dashboard-creation)\n",
    "- [Conclusion](#conclusion)\n",
    "        \n",
    "## Data Overview\n",
    "    The dataset contains sales records from a pharmaceutical company, including details about products, distributors, sales representatives, sales and price figures.\n",
    "The original dataset has 254,083 rows and 18 columns. After cleaning, it has 218,928 and 18 columns. The cleaned dataset is further used for analysis, modeling, and \n",
    "also used in the creation of a dashboard report PowerBI.\n",
    "The cleaned dataset is saved as 'cleaned_pharma_data.csv', and the original dataset is 'pharma-data.csv'. \n",
    "**Columns**:\n",
    "- Distributor\n",
    "- Customer Name\n",
    "- City\n",
    "- Country\n",
    "- Channel\n",
    "- Sub-channel\n",
    "- Product Name\n",
    "- Product Class\n",
    "- Quantity\n",
    "- Price\n",
    "- Sales\n",
    "- Month\n",
    "- Year\n",
    "- Name of Sales Rep\n",
    "- Manager\n",
    "- Sales Team\n",
    "- Quantity_Price (Engineered Feature)\n",
    "        \n",
    "## Data Cleaning\n",
    "The data cleaning process involved:\n",
    "- Handling errors in 'Quantity' and 'Sales' columns by converting to absolute values.\n",
    "- Fixing data type error by converting 'Quantity', 'Sales', and 'Price' columns to numeric types.\n",
    "- Removing duplicates (there were 4 duplicates).\n",
    "- Identifying and removing outliers in 'Sales' and 'Quantity' columns using the IQR method.\n",
    "- Final cleaned dataset has 218,928 rows and 18 columns.\n",
    "        \n",
    "## Exploratory Data Analysis (EDA)\n",
    "EDA was performed to understand the data distribution and relationships:\n",
    "- Descriptive statistics were generated for numerical columns.\n",
    "- Correlation analysis showed strong correlation between 'Sales' and 'Price'. However, 'Quantity' had the strongest correlation with 'Sales'.\n",
    "- Visualizations included bar plots, pie charts, and line plots to analyze sales by product name and class, channel, year, month, distributor, and sales rep and team.\n",
    "- Further analysis was done to understand the quantity sold by distributors.\n",
    "- Key insights were drawn from the visualizations to inform feature selection and engineering.\n",
    "Visuals created during EDA were saved as PNG files and are saved in the \"visual outputs\" directory.\n",
    "        \n",
    "## Machine Learning Models\n",
    "Two separate XGBoost regression models were developed:\n",
    "1. **Price Prediction Model**: Predicts the price of pharmaceutical products based on various features but excluding 'Quanity', 'Quantity_Price', and 'Sales'.\n",
    "2. **Sales Prediction Model**: Predicts sales figures using all relevant features including 'Quantity', 'Price' and 'Quantity_Price'.\n",
    "Both models were trained and evaluated using metrics such as RMSE, MAE, and R2 Score.\n",
    "        \n",
    "## Data Preprocessing\n",
    "Data preprocessing steps included:\n",
    "- Encoding categorical variables using Label Encoding.\n",
    "- Scaling numerical features ('Quantity' and 'Year') using StandardScaler. Taget variables ('Price' and 'Sales') were not scaled.\n",
    "- Splitting the data into training and testing sets (80-20 split). The random state was set to 42 for better results.\n",
    "        \n",
    "## Feature Engineering\n",
    "Although by default 'Sales' is as a result of multiplying 'Price' by 'Quantity', an additional feature 'Quantity_Price' was created by multiplying 'Quantity' and 'Price'.\n",
    "This feature was used in the Sales Prediction Model to improve the accuracy of the sales model and predictions.\n",
    "        \n",
    "## Model Training & Evaluation\n",
    "Both models were trained using the XGBoost regressor with hyperparameters optimized through cross-validation.\n",
    "The models were evaluated on the test set using:\n",
    "- Mean Squared Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "- Mean Absolute Error (MAE)\n",
    "- R2 Score\n",
    "- Cross-validation results were also analyzed to ensure model robustness and inspect for overfitting or underfitting.\n",
    "The Sales model suffered from overfitting while the price model had slight underfitting. Hyperparameters were adjusted to mitigate these issues.\n",
    "After the hyperparameter tuning, the models were able to generalize well on unseen data and the issues of overfitting and underfitting were resolved.\n",
    "However, the sales model still has errors (MSE, MAE) due to the complexity of sales data.\n",
    "The evaluations metrics for both models are summarized below:\n",
    "- **Price Model**:\n",
    "- mse_price = {mse_price:.2f}\n",
    "- rmse_price = {rmse_price:.2f}\n",
    "- mae_sales = {mae_price:.2f}\n",
    "- r2_sales = {r2_price:.2f}\n",
    "- Cross-validation for price model:\n",
    "cv_price = {cv_price}\n",
    "- **Sales Model**:\n",
    "- mse_sales = {mse_sales:.2f}   \n",
    "- rmse_sales = {rmse_sales:.2f} \n",
    "- mae_sales = {mae_sales:.2f}\n",
    "- r2_sales = {r2_sales:.2f}\n",
    "- Cross-validation for sales model:\n",
    "cv_sales = {cv_sales}\n",
    "        \n",
    "## Feature Importance\n",
    "Feature importance was analyzed for both models to understand which features had the most impact on predictions.\n",
    "- For the Price Model, 'Product Name' and 'Product Class' were the most important features.\n",
    "- For the Sales Model, 'Price', 'Quantity', 'Product Class' and 'Product Name' were the top features.\n",
    "Visualizations of feature importance were created to aid interpretation.\n",
    "\n",
    "## Predictions on New Data\n",
    "The trained models were used to make predictions on existing data points and also on new data points. \n",
    "Due to the complexity of sales data, the sales model had some errors in predictions so the price model was used to predict price and then the results for sales was \n",
    "calculated by multiplying the predicted price by the quantity.\n",
    "An example of existing data used for predictions:\n",
    "- Distributor: 'Gottlieb-Cruickshank'\n",
    "- Customer Name: 'Keeling LLC Pharmacy'\n",
    "- City: 'Olsztyn'\n",
    "- Country: 'Poland'\n",
    "- Channel: 'Pharmacy'\n",
    "- Sub-channel: 'Private'\n",
    "- Product Name: 'Oxymotroban Fexoformin'\n",
    "- Product Class: 'Analgesics'\n",
    "- Quantity: 20.0\n",
    "- Month: 'January'\n",
    "- Year: 2018\n",
    "- Name of Sales Rep: 'Anne Wu'\n",
    "- Manager: 'Britanny Bold'\n",
    "- Sales Team: 'Delta'\n",
    "    The predicted results were:\n",
    "- Predicted Sales ($): 9160\n",
    "- Predicted Price ($): 458\n",
    "The results were rounded to the nearesr integer for simplicity and they were exactly the same as the actual values.\n",
    "        \n",
    "## Model Artifacts\n",
    "All components of the pipeline were saved using joblib for future use. This includes:\n",
    "- Trained models (Sales and Price)\n",
    "- Label encoders for categorical variables\n",
    "- StandardScaler for numerical features\n",
    "- Feature lists for both models\n",
    "- Feature importance dataframes for both models.\n",
    "The artifacts are saved in the 'model_artifacts' directory.\n",
    "        \n",
    "## Dashboard Creation\n",
    "A dashboard was created using PowerBI to visualize key insights from the data. The dashboard includes:\n",
    "- Sales by Product Class\n",
    "- Sales by Channel and Sub-channel\n",
    "- Sales by Year and Month\n",
    "- Sales by Distributor and Country\n",
    "- Sales by Sales Rep and Sales Team\n",
    "The dashboard provides an interactive way to explore the data and understand sales trends.\n",
    "The cleaned dataset 'cleaned_pharma_data.csv' was used as the data source for the dashboard.\n",
    "The PowerBI dashboard file is saved as 'Pharma Sales Dashboard.pbix'.\n",
    "        \n",
    "## Conclusion\n",
    "This project successfully demonstrated the end-to-end process of data cleaning, exploratory data analysis, feature engineering, model training and evaluation, \n",
    "and dashboard creation for pharmaceutical sales data. \n",
    "The developed models can be used for predicting sales and prices, and the dashboard provides valuable insights for decision-making.\n",
    "\n",
    "**Note**: The models, while effective, may still have limitations due to the inherent complexity and variability in sales data.\n",
    "        \n",
    "**Connect with me**:\n",
    "- [LinkedIn](https://www.linkedin.com/in/ireoluwawolemi-akindipe-16b711373?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app)\n",
    "- [GitHub](https://github.com/Dhela456)\n",
    "\n",
    "\"\"\".format(mse_price=mse_price, rmse_price=rmse_price, mae_price=mae_price, r2_price=r2_price, cv_price=price_cv.tail() if 'price_cv' in locals() else 'N/A',\n",
    "           mse_sales=mse_sales, rmse_sales=rmse_sales, mae_sales=mae_sales, r2_sales=r2_sales, cv_sales=sales_cv.tail() if 'price_cv' in locals() else 'N/A'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
